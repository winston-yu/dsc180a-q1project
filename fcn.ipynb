{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcn import TwoLayerFCN\n",
    "from fcn_edge import TwoLayerFCNEdge\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Cora'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node classification with FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid('./data', data_name, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, num_features = data.x.size()\n",
    "num_classes = len(data.y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "y = F.one_hot(data.y)\n",
    "y_tr, y_val, y_te = y[data.train_mask], y[data.val_mask], y[data.test_mask]\n",
    "y_tr = torch.cat([y_tr, torch.zeros(size=(num_nodes - y_tr.shape[0], num_classes))], axis=0)\n",
    "y_val = torch.cat([y_val, torch.zeros(size=(num_nodes - y_val.shape[0], num_classes))], axis=0)\n",
    "y_te = torch.cat([y_te, torch.zeros(size=(num_nodes - y_te.shape[0], num_classes))], axis=0)\n",
    "\n",
    "X = data.x\n",
    "X_tr, X_val, X_te = X[data.train_mask], X[data.val_mask], X[data.test_mask]\n",
    "X_tr = torch.cat([X_tr, torch.zeros(size=(num_nodes - X_tr.shape[0], num_features))], axis=0)\n",
    "X_val = torch.cat([X_val, torch.zeros(size=(num_nodes - X_val.shape[0], num_features))], axis=0)\n",
    "X_te = torch.cat([X_te, torch.zeros(size=(num_nodes - X_te.shape[0], num_features))], axis=0)\n",
    "\n",
    "tr_shuffle, val_shuffle, te_shuffle = torch.randperm(num_nodes), torch.randperm(num_nodes), torch.randperm(num_nodes)\n",
    "X_tr, X_val, X_te = X_tr[tr_shuffle], X_val[val_shuffle], X_te[te_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Training CE: 1.945910; Validation CE: 1.401050; Training ACC: 0.151773; Validation ACC: 0.147341\n",
      "Epoch  20 | Training CE: 1.915074; Validation CE: 1.407285; Training ACC: 0.287297; Validation ACC: 0.292097\n",
      "Epoch  40 | Training CE: 1.911815; Validation CE: 1.407049; Training ACC: 0.529911; Validation ACC: 0.471935\n",
      "Epoch  60 | Training CE: 1.920423; Validation CE: 1.403476; Training ACC: 0.753323; Validation ACC: 0.669498\n",
      "Epoch  80 | Training CE: 1.906999; Validation CE: 1.404551; Training ACC: 0.825702; Validation ACC: 0.719719\n",
      "Epoch 100 | Training CE: 1.911252; Validation CE: 1.402851; Training ACC: 0.865583; Validation ACC: 0.756647\n",
      "Epoch 120 | Training CE: 1.912264; Validation CE: 1.402810; Training ACC: 0.888109; Validation ACC: 0.773264\n",
      "Epoch 140 | Training CE: 1.916586; Validation CE: 1.402214; Training ACC: 0.888479; Validation ACC: 0.769202\n",
      "Epoch 160 | Training CE: 1.913640; Validation CE: 1.403581; Training ACC: 0.916544; Validation ACC: 0.797267\n",
      "Epoch 180 | Training CE: 1.912840; Validation CE: 1.401238; Training ACC: 0.920236; Validation ACC: 0.797637\n",
      "Epoch 200 | Training CE: 1.916079; Validation CE: 1.403570; Training ACC: 0.902511; Validation ACC: 0.783235\n",
      "Epoch 220 | Training CE: 1.915932; Validation CE: 1.403899; Training ACC: 0.914697; Validation ACC: 0.793205\n",
      "Epoch 240 | Training CE: 1.911297; Validation CE: 1.402819; Training ACC: 0.926514; Validation ACC: 0.804284\n",
      "Epoch 260 | Training CE: 1.912659; Validation CE: 1.402740; Training ACC: 0.927622; Validation ACC: 0.808715\n",
      "Epoch 280 | Training CE: 1.916393; Validation CE: 1.402809; Training ACC: 0.933900; Validation ACC: 0.810931\n",
      "Epoch 300 | Training CE: 1.915868; Validation CE: 1.401757; Training ACC: 0.928730; Validation ACC: 0.810561\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "epochs = 300\n",
    "print_every = 20\n",
    "\n",
    "model = TwoLayerFCN(num_classes, num_features, num_nodes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    shuffle = torch.randperm(num_nodes)\n",
    "    shuffle_mask = data.train_mask[shuffle]\n",
    "    \n",
    "    inputs, train_targets = X_tr[shuffle].to(device), y_tr[shuffle].to(device)\n",
    "    train_preds = model(inputs)\n",
    "    train_loss = loss_fn(train_preds[shuffle_mask], train_targets[shuffle_mask])\n",
    "    train_acc = (train_preds.argmax(axis=1) == train_targets.argmax(axis=1)).float().mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        shuffle = torch.randperm(num_nodes)\n",
    "        shuffle_mask = data.val_mask[shuffle]\n",
    "\n",
    "        inputs, val_targets = X_val[shuffle].to(device), y_val[shuffle].to(device)\n",
    "        val_preds = model(inputs)\n",
    "        val_loss = loss_fn(val_preds[shuffle_mask], val_targets[shuffle_mask])\n",
    "        val_acc = (val_preds.argmax(axis=1) == val_targets.argmax(axis=1)).float().mean()\n",
    "\n",
    "    if t % print_every == 0 or t == 1: print(\n",
    "        'Epoch {:3d}'.format(t) \n",
    "        + ' | tr xe: {:.6f}; val xe: {:.6f};'.format(train_loss.item(), val_loss.item())\n",
    "        + ' tr acc: {:.6f}; val acc: {:.6f}'.format(train_acc.item(), val_acc.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link prediction with FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid('./data', data_name, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, num_features = data.x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.x\n",
    "A = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.edge_index.shape[1])).to_dense()\n",
    "\n",
    "# separate into train, val, test\n",
    "X_tr, X_val, X_te = X[data.train_mask], X[data.val_mask], X[data.test_mask]\n",
    "A_tr, A_val, A_te = A[data.train_mask], A[data.val_mask], A[data.test_mask]\n",
    "\n",
    "# get indices of train, val, test\n",
    "mask_tr = torch.cat([torch.ones(len(X_tr)), torch.zeros(num_nodes - len(X_tr))]).bool()\n",
    "mask_val = torch.cat([torch.ones(len(X_val)), torch.zeros(num_nodes - len(X_val))]).bool()\n",
    "mask_te = torch.cat([torch.ones(len(X_te)), torch.zeros(num_nodes - len(X_te))]).bool()\n",
    "\n",
    "# fix shapes\n",
    "X_tr = torch.cat([X_tr, torch.zeros(size=(num_nodes - X_tr.shape[0], num_features))], axis=0)\n",
    "A_tr = torch.cat([A_tr, torch.zeros(size=(num_nodes - A_tr.shape[0], num_nodes))], axis=0)\n",
    "\n",
    "X_val = torch.cat([X_val, torch.zeros(size=(num_nodes - X_val.shape[0], num_features))], axis=0)\n",
    "A_val = torch.cat([A_val, torch.zeros(size=(num_nodes - A_val.shape[0], num_nodes))], axis=0)\n",
    "\n",
    "X_te = torch.cat([X_te, torch.zeros(size=(num_nodes - X_te.shape[0], num_features))], axis=0)\n",
    "A_te = torch.cat([A_te, torch.zeros(size=(num_nodes - A_te.shape[0], num_nodes))], axis=0)\n",
    "\n",
    "# permute\n",
    "shuffle_tr, shuffle_val, shuffle_te = torch.randperm(num_nodes), torch.randperm(num_nodes), torch.randperm(num_nodes)\n",
    "X_tr, X_val, X_te = X_tr[shuffle_tr], X_val[shuffle_val], X_te[shuffle_te]\n",
    "A_tr, A_val, A_te = A_tr[shuffle_tr], A_val[shuffle_val], A_te[shuffle_te]\n",
    "mask_tr, mask_val, mask_te = mask_tr[shuffle_tr], mask_val[shuffle_val], mask_te[shuffle_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(targets, preds, mask):\n",
    "    edge_rows, edge_cols = targets[mask].nonzero().t()\n",
    "    tp = len(targets[mask].nonzero()[:, 0])\n",
    "    fp = len((targets[mask][~edge_rows, ~edge_cols] != preds[mask][~edge_rows, ~edge_cols].round()).nonzero())\n",
    "    fn = len((targets[mask][edge_rows, edge_cols] != preds[mask][edge_rows, edge_cols].round()).nonzero())\n",
    "    prec, recall = tp / (tp + fp), tp / (tp + fn)\n",
    "    return prec, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | tr xe: 0.5081; val xe: 30.7939; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5008; val prec: 0.5005\n",
      "Epoch  15 | tr xe: 1.2421; val xe: 30.7938; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5016; val prec: 0.5008\n",
      "Epoch  30 | tr xe: 1.4679; val xe: 30.7938; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5000; val prec: 0.5005\n",
      "Epoch  45 | tr xe: 3.7261; val xe: 30.7938; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5000; val prec: 0.5005\n",
      "Epoch  60 | tr xe: 2.2583; val xe: 30.7938; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5016; val prec: 0.5000\n",
      "Epoch  75 | tr xe: 1.2420; val xe: 30.7938; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5024; val prec: 0.5013\n",
      "Epoch  90 | tr xe: 1.9759; val xe: 30.7938; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5004; val prec: 0.5003\n",
      "Epoch 105 | tr xe: 0.7339; val xe: 30.7937; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5000; val prec: 0.5003\n",
      "Epoch 120 | tr xe: 2.5405; val xe: 30.7937; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5008; val prec: 0.5008\n",
      "Epoch 135 | tr xe: 1.4113; val xe: 30.7935; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5000; val prec: 0.5003\n",
      "Epoch 150 | tr xe: 1.1289; val xe: 30.7932; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5008; val prec: 0.5005\n",
      "Epoch 165 | tr xe: 0.9029; val xe: 30.7923; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5012; val prec: 0.5003\n",
      "Epoch 180 | tr xe: 2.2538; val xe: 30.7910; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5008; val prec: 0.5036\n",
      "Epoch 195 | tr xe: 1.1835; val xe: 30.7858; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5158; val prec: 0.5140\n",
      "Epoch 210 | tr xe: 1.9632; val xe: 30.7782; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.5557; val prec: 0.5567\n",
      "Epoch 225 | tr xe: 2.1913; val xe: 30.7670; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.6457; val prec: 0.6282\n",
      "Epoch 240 | tr xe: 1.1657; val xe: 30.7585; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.7185; val prec: 0.6745\n",
      "Epoch 255 | tr xe: 1.7135; val xe: 30.7576; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.7453; val prec: 0.7138\n",
      "Epoch 270 | tr xe: 6.1636; val xe: 30.7409; tr recall: 0.9984; val recall: 0.9984; tr prec: 0.7577; val prec: 0.7178\n",
      "Epoch 285 | tr xe: 1.5471; val xe: 30.7451; tr recall: 1.0000; val recall: 1.0000; tr prec: 0.7715; val prec: 0.7282\n",
      "Epoch 300 | tr xe: 0.4394; val xe: 30.7297; tr recall: 0.9938; val recall: 0.9938; tr prec: 0.7752; val prec: 0.7332\n",
      "Epoch 315 | tr xe: 3.1737; val xe: 30.7364; tr recall: 0.9907; val recall: 0.9907; tr prec: 0.7705; val prec: 0.7261\n",
      "Epoch 330 | tr xe: 0.8706; val xe: 30.7368; tr recall: 0.9876; val recall: 0.9876; tr prec: 0.7762; val prec: 0.7365\n",
      "Epoch 345 | tr xe: 4.4447; val xe: 30.7333; tr recall: 0.9815; val recall: 0.9815; tr prec: 0.7743; val prec: 0.7379\n",
      "Epoch 360 | tr xe: 1.2007; val xe: 30.7369; tr recall: 0.9831; val recall: 0.9831; tr prec: 0.7828; val prec: 0.7472\n",
      "Epoch 375 | tr xe: 1.5798; val xe: 30.7299; tr recall: 0.9846; val recall: 0.9846; tr prec: 0.7762; val prec: 0.7510\n",
      "Epoch 390 | tr xe: 1.2467; val xe: 30.7405; tr recall: 0.9755; val recall: 0.9755; tr prec: 0.7838; val prec: 0.7464\n",
      "Epoch 405 | tr xe: 3.4106; val xe: 30.7288; tr recall: 0.9800; val recall: 0.9800; tr prec: 0.7762; val prec: 0.7370\n",
      "Epoch 420 | tr xe: 3.8056; val xe: 30.7456; tr recall: 0.9327; val recall: 0.9327; tr prec: 0.7935; val prec: 0.7452\n",
      "Epoch 435 | tr xe: 1.5121; val xe: 30.7354; tr recall: 0.9770; val recall: 0.9770; tr prec: 0.7800; val prec: 0.7429\n",
      "Epoch 450 | tr xe: 2.4858; val xe: 30.7200; tr recall: 0.9846; val recall: 0.9846; tr prec: 0.7809; val prec: 0.7407\n",
      "Epoch 465 | tr xe: 1.2427; val xe: 30.7288; tr recall: 0.9938; val recall: 0.9938; tr prec: 0.7743; val prec: 0.7370\n",
      "Epoch 480 | tr xe: 2.0617; val xe: 30.7436; tr recall: 0.9953; val recall: 0.9953; tr prec: 0.7762; val prec: 0.7481\n",
      "Epoch 495 | tr xe: 0.9812; val xe: 30.7325; tr recall: 0.9711; val recall: 0.9711; tr prec: 0.7867; val prec: 0.7507\n",
      "Epoch 510 | tr xe: 2.9804; val xe: 30.7301; tr recall: 0.9740; val recall: 0.9740; tr prec: 0.7916; val prec: 0.7478\n",
      "Epoch 525 | tr xe: 1.1347; val xe: 30.7396; tr recall: 0.9800; val recall: 0.9800; tr prec: 0.7743; val prec: 0.7583\n",
      "Epoch 540 | tr xe: 3.9469; val xe: 30.7315; tr recall: 0.9770; val recall: 0.9770; tr prec: 0.7687; val prec: 0.7627\n",
      "Epoch 555 | tr xe: 3.2459; val xe: 30.7304; tr recall: 0.9580; val recall: 0.9580; tr prec: 0.7762; val prec: 0.7592\n",
      "Epoch 570 | tr xe: 1.6216; val xe: 30.7287; tr recall: 0.9831; val recall: 0.9831; tr prec: 0.7780; val prec: 0.7458\n",
      "Epoch 585 | tr xe: 2.4280; val xe: 30.7305; tr recall: 0.9522; val recall: 0.9522; tr prec: 0.7809; val prec: 0.7706\n",
      "Epoch 600 | tr xe: 1.5796; val xe: 30.7252; tr recall: 0.9551; val recall: 0.9551; tr prec: 0.7935; val prec: 0.7678\n",
      "test recall: 0.6688; test prec: 0.7041\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epochs = 600\n",
    "print_every = 15\n",
    "\n",
    "model = TwoLayerFCNEdge(num_nodes, num_features, num_features // 4, num_features // 16).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    shuffle = torch.randperm(num_nodes)\n",
    "    input, targets, shuffle_mask = X_tr[shuffle].to(device), A_tr[shuffle].to(device), mask_tr[shuffle]\n",
    "    preds = model(input)\n",
    "    train_loss = loss_fn(preds[mask_tr], targets[mask_tr])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        shuffle = torch.randperm(num_nodes)\n",
    "\n",
    "        inputs, targets, shuffle_mask = X_tr[shuffle].to(device), A_tr[shuffle].to(device), mask_tr[shuffle]\n",
    "        preds = model(inputs)\n",
    "        tr_prec, tr_rcll = report(targets, preds, shuffle_mask)\n",
    "\n",
    "        input, targets, shuffle_mask = X_val[shuffle].to(device), A_val[shuffle].to(device), mask_val[shuffle]\n",
    "        preds = model(input)\n",
    "        val_loss = loss_fn(preds[shuffle_mask], targets[shuffle_mask])\n",
    "        val_prec, val_rcll = report(targets, preds, shuffle_mask)\n",
    "\n",
    "    if t % print_every == 0 or t == 1: print(\n",
    "        'Epoch {:3d} | '.format(t) \n",
    "        + 'tr xe: {:.4f}; val xe: {:.4f}; '.format(train_loss.item(), val_loss.item())\n",
    "        + 'tr recall: {:.4f}; val recall: {:.4f}; '.format(tr_rcll, tr_rcll)\n",
    "        + 'tr prec: {:.4f}; val prec: {:.4f}'.format(tr_prec, val_prec) \n",
    "    )\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs, targets = X_te.to(device), A_te.to(device)\n",
    "    preds = model(inputs)\n",
    "    test_prec, test_rcll = report(targets, preds, mask_te)\n",
    "    print('test recall: {:.4f}; test prec: {:.4f}'.format(test_rcll, test_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10556/10556 [00:01<00:00, 7764.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# X, y = [], []\n",
    "# existing_edges = [data.edge_index[:, i] for i in range(data.edge_index.shape[1])]\n",
    "# for e in tqdm(existing_edges):\n",
    "#     n1, n2 = e\n",
    "#     # positive sample\n",
    "#     X.append((data.x[n1] - data.x[n2]).abs())\n",
    "#     y.append(torch.Tensor([1,0]))\n",
    "\n",
    "#     # negative sample\n",
    "#     not_n1_neighbors = data.edge_index[1, data.edge_index[0] != n1]\n",
    "#     random_idx = np.random.choice(len(not_n1_neighbors))\n",
    "#     X.append((data.x[n1] - data.x[not_n1_neighbors[random_idx]]).abs())\n",
    "#     y.append(torch.Tensor([0,1]))\n",
    "\n",
    "# num_samples = len(X)\n",
    "# tr, val, te = int(0.7 * num_samples), int(0.15 * num_samples), int(0.15 * num_samples)\n",
    "# X_tr, X_val, X_te = X[:tr], X[tr:(tr + val)], X[(tr + val):]\n",
    "# y_tr, y_val, y_te = y[:tr], y[tr:(tr + val)], y[(tr + val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# trainDataLoader = DataLoader(\n",
    "#     [(input, target) for input, target in zip(X_tr, y_tr)],\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "# valDataLoader = DataLoader(\n",
    "#     [(input, target) for input, target in zip(X_val, y_val)],\n",
    "#     shuffle=True,\n",
    "#     batch_size=len(X_val)\n",
    "# )\n",
    "# testDataLoader = DataLoader(\n",
    "#     [(input, target) for input, target in zip(X_te, y_te)],\n",
    "#     shuffle=True,\n",
    "#     batch_size=len(X_te)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Training CE: 0.624491; Validation CE: 0.645586; Training ACC: 0.692308; Validation ACC: 0.639292\n",
      "Epoch   5 | Training CE: 0.467465; Validation CE: 0.567438; Training ACC: 0.846154; Validation ACC: 0.728996\n",
      "Epoch  10 | Training CE: 0.469128; Validation CE: 0.522194; Training ACC: 0.846154; Validation ACC: 0.783007\n",
      "Epoch  15 | Training CE: 0.390870; Validation CE: 0.502896; Training ACC: 0.923077; Validation ACC: 0.808275\n",
      "Epoch  20 | Training CE: 0.390542; Validation CE: 0.515589; Training ACC: 0.923077; Validation ACC: 0.790903\n",
      "Epoch  25 | Training CE: 0.474843; Validation CE: 0.520048; Training ACC: 0.846154; Validation ACC: 0.787429\n",
      "Epoch  30 | Training CE: 0.391237; Validation CE: 0.526192; Training ACC: 0.923077; Validation ACC: 0.783955\n",
      "Epoch  35 | Training CE: 0.313303; Validation CE: 0.496157; Training ACC: 1.000000; Validation ACC: 0.814277\n",
      "Epoch  40 | Training CE: 0.313309; Validation CE: 0.514026; Training ACC: 1.000000; Validation ACC: 0.796589\n",
      "Epoch  45 | Training CE: 0.353093; Validation CE: 0.545527; Training ACC: 0.961538; Validation ACC: 0.764687\n",
      "Epoch  50 | Training CE: 0.351722; Validation CE: 0.526819; Training ACC: 0.961538; Validation ACC: 0.782691\n",
      "Epoch  55 | Training CE: 0.313273; Validation CE: 0.506030; Training ACC: 1.000000; Validation ACC: 0.803222\n",
      "Epoch  60 | Training CE: 0.313274; Validation CE: 0.508215; Training ACC: 1.000000; Validation ACC: 0.803222\n",
      "Epoch  65 | Training CE: 0.351737; Validation CE: 0.538798; Training ACC: 0.961538; Validation ACC: 0.772900\n",
      "Epoch  70 | Training CE: 0.313274; Validation CE: 0.563651; Training ACC: 1.000000; Validation ACC: 0.746999\n",
      "Epoch  75 | Training CE: 0.351734; Validation CE: 0.509235; Training ACC: 0.961538; Validation ACC: 0.800379\n"
     ]
    }
   ],
   "source": [
    "# lr = 1e-3\n",
    "# epochs = 75\n",
    "# print_every = 5\n",
    "\n",
    "# model = TwoLayerFCNEdge(num_features, num_features // 2, num_features // 4).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# for t in range(1, epochs + 1):\n",
    "#     for X, y in trainDataLoader:\n",
    "#         inputs, targets = X.to(device), y.to(device)\n",
    "#         train_preds = model(inputs)\n",
    "#         train_loss = loss_fn(train_preds, targets)\n",
    "#         train_acc = (train_preds.argmax(axis=1) == targets.argmax(axis=1)).float().mean()\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for X_sg, y_sg in valDataLoader: # has length of 1 because why not\n",
    "#             X_sg, y_sg = X_sg.to(device), y_sg.to(device)\n",
    "#             val_preds = model(X_sg)\n",
    "#             val_loss = loss_fn(val_preds, y_sg)\n",
    "#             val_acc = (val_preds.argmax(axis=1) == y_sg.argmax(axis=1)).float().mean()\n",
    "\n",
    "#     if t % print_every == 0 or t == 1: print(\n",
    "#         'Epoch {:3d} | '.format(t) \n",
    "#         + 'Training CE: {:.6f}; Validation CE: {:.6f}; '.format(train_loss.item(), val_loss.item())\n",
    "#         + 'Training ACC: {:.6f}; Validation ACC: {:.6f}'.format(train_acc.item(), val_acc.item())\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsc80')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eb5c4403b148c92508d1229a3ce9db6ac989f594d65cf46884d2594c7385210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
