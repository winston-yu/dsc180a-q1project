{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn import TwoLayerGCN\n",
    "from gcn_edge import TwoLayerGCNEdge\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Pubmed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node classification with GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid('./data', data_name, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, num_features = data.x.size()\n",
    "num_classes = len(data.y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.x\n",
    "y = F.one_hot(data.y)\n",
    "\n",
    "# separate train, val, test\n",
    "X_tr, X_val, X_te = X[data.train_mask], X[data.val_mask], X[data.test_mask]\n",
    "y_tr, y_val, y_te = y[data.train_mask], y[data.val_mask], y[data.test_mask]\n",
    "\n",
    "# get indices of train, val, test\n",
    "mask_tr = torch.cat([torch.ones(len(X_tr)), torch.zeros(num_nodes - len(X_tr))]).bool()\n",
    "mask_val = torch.cat([torch.ones(len(X_val)), torch.zeros(num_nodes - len(X_val))]).bool()\n",
    "mask_te = torch.cat([torch.ones(len(X_te)), torch.zeros(num_nodes - len(X_te))]).bool()\n",
    "\n",
    "# fix shapes\n",
    "X_tr = torch.cat([X_tr, torch.zeros(size=(num_nodes - X_tr.shape[0], num_features))])\n",
    "y_tr = torch.cat([y_tr, -torch.ones(size=(num_nodes - y_tr.shape[0], num_classes))])\n",
    "\n",
    "X_val = torch.cat([X_val, torch.zeros(size=(num_nodes - X_val.shape[0], num_features))])\n",
    "y_val = torch.cat([y_val, -torch.ones(size=(num_nodes - y_val.shape[0], num_classes))])\n",
    "\n",
    "X_te = torch.cat([X_te, torch.zeros(size=(num_nodes - X_te.shape[0], num_features))])\n",
    "y_te = torch.cat([y_te, -torch.ones(size=(num_nodes - y_te.shape[0], num_classes))])\n",
    "\n",
    "torch.manual_seed(41)\n",
    "\n",
    "# get permutations\n",
    "shuffle_tr, shuffle_val, shuffle_te = torch.randperm(num_nodes), torch.randperm(num_nodes), torch.randperm(num_nodes)\n",
    "X_tr, X_val, X_te = X_tr[shuffle_tr], X_val[shuffle_val], X_te[shuffle_te]\n",
    "y_tr, y_val, y_te = y_tr[shuffle_tr], y_val[shuffle_val], y_te[shuffle_te]\n",
    "mask_tr, mask_val, mask_te = mask_tr[shuffle_tr], mask_val[shuffle_val], mask_te[shuffle_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "epochs = 300\n",
    "print_every = 15\n",
    "\n",
    "A = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.edge_index.shape[1]))\n",
    "model = TwoLayerGCN(A, num_classes, num_features, p=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    shuffle = torch.randperm(num_nodes)\n",
    "    \n",
    "    inputs, targets, shuffle_mask = X_tr[shuffle].to(device), y_tr[shuffle].to(device), mask_tr[shuffle]\n",
    "    preds = model(inputs)\n",
    "    train_loss = loss_fn(preds[shuffle_mask], targets[shuffle_mask])\n",
    "    train_acc = (\n",
    "        preds[shuffle_mask].argmax(axis=1) == targets[shuffle_mask].argmax(axis=1)\n",
    "    ).float().mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        shuffle = torch.randperm(num_nodes)\n",
    "\n",
    "        inputs, targets, shuffle_mask = X_val[shuffle].to(device), y_val[shuffle].to(device), mask_val[shuffle]\n",
    "        preds = model(inputs)\n",
    "        val_loss = loss_fn(preds[shuffle_mask], targets[shuffle_mask])\n",
    "        val_acc = (\n",
    "            preds[shuffle_mask].argmax(axis=1) == targets[shuffle_mask].argmax(axis=1)\n",
    "        ).float().mean()\n",
    "\n",
    "    if t % print_every == 0 or t == 1: print(\n",
    "        'Epoch {:3d} | '.format(t) \n",
    "        + 'tr xe: {:.6f}; val xe: {:.6f}; '.format(train_loss.item(), val_loss.item())\n",
    "        + 'tr acc: {:.4f}; val acc: {:.4f}'.format(train_acc.item(), val_acc.item())\n",
    "    )\n",
    "model.eval()\n",
    "test_acc = (model(X_te)[mask_te].argmax(axis=1) == y_te[mask_te].argmax(axis=1)).float().mean()\n",
    "print('test acc: {:4f}'.format(test_acc.item()))\n",
    "# for some reason GCN takes 14 seconds to initialize on Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Classification with GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Planetoid('./data', data_name, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, num_features = data.x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.x\n",
    "A = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.edge_index.shape[1])).to_dense()\n",
    "\n",
    "# separate into train, val, test\n",
    "X_tr, X_val, X_te = X[data.train_mask], X[data.val_mask], X[data.test_mask]\n",
    "A_tr, A_val, A_te = A[data.train_mask], A[data.val_mask], A[data.test_mask]\n",
    "\n",
    "# get indices of train, val, test\n",
    "mask_tr = torch.cat([torch.ones(len(X_tr)), torch.zeros(num_nodes - len(X_tr))]).bool()\n",
    "mask_val = torch.cat([torch.ones(len(X_val)), torch.zeros(num_nodes - len(X_val))]).bool()\n",
    "mask_te = torch.cat([torch.ones(len(X_te)), torch.zeros(num_nodes - len(X_te))]).bool()\n",
    "\n",
    "# fix shapes\n",
    "X_tr = torch.cat([X_tr, torch.zeros(size=(num_nodes - X_tr.shape[0], num_features))], axis=0)\n",
    "A_tr = torch.cat([A_tr, torch.zeros(size=(num_nodes - A_tr.shape[0], num_nodes))], axis=0)\n",
    "\n",
    "X_val = torch.cat([X_val, torch.zeros(size=(num_nodes - X_val.shape[0], num_features))], axis=0)\n",
    "A_val = torch.cat([A_val, torch.zeros(size=(num_nodes - A_val.shape[0], num_nodes))], axis=0)\n",
    "\n",
    "X_te = torch.cat([X_te, torch.zeros(size=(num_nodes - X_te.shape[0], num_features))], axis=0)\n",
    "A_te = torch.cat([A_te, torch.zeros(size=(num_nodes - A_te.shape[0], num_nodes))], axis=0)\n",
    "\n",
    "# permute\n",
    "shuffle_tr, shuffle_val, shuffle_te = torch.randperm(num_nodes), torch.randperm(num_nodes), torch.randperm(num_nodes)\n",
    "X_tr, X_val, X_te = X_tr[shuffle_tr], X_val[shuffle_val], X_te[shuffle_te]\n",
    "A_tr, A_val, A_te = A_tr[shuffle_tr], A_val[shuffle_val], A_te[shuffle_te]\n",
    "mask_tr, mask_val, mask_te = mask_tr[shuffle_tr], mask_val[shuffle_val], mask_te[shuffle_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(targets, preds, mask):\n",
    "    edge_rows, edge_cols = targets[mask].nonzero().t()\n",
    "    tp = len(targets[mask].nonzero()[:, 0])\n",
    "    fp = len((targets[mask][~edge_rows, ~edge_cols] != preds[mask][~edge_rows, ~edge_cols].round()).nonzero())\n",
    "    fn = len((targets[mask][edge_rows, edge_cols] != preds[mask][edge_rows, edge_cols].round()).nonzero())\n",
    "    prec, recall = tp / (tp + fp), tp / (tp + fn)\n",
    "    return prec, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-7 # somehow 1e-12 works well\n",
    "epochs = 500\n",
    "print_every = 20\n",
    "\n",
    "if data_name == 'Cora':\n",
    "    model = TwoLayerGCNEdge(A_tr, num_features, num_features // 4, num_features // 16, p=0.5).to(device)\n",
    "elif data_name == 'Pubmed':\n",
    "    model = TwoLayerGCNEdge(A_tr, num_features, 64, 16, p=0).to(device)\n",
    "print('model initialized.')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    shuffle = torch.randperm(num_nodes)\n",
    "    inputs, targets, shuffle_mask = X_tr[shuffle].to(device), A_tr[shuffle].to(device), mask_tr[shuffle]\n",
    "    preds = model(inputs)\n",
    "    train_loss = loss_fn(preds[shuffle_mask], targets[shuffle_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        shuffle = torch.randperm(num_nodes)\n",
    "\n",
    "        inputs, targets, shuffle_mask = X_tr[shuffle].to(device), A_tr[shuffle].to(device), mask_tr[shuffle]\n",
    "        preds = model(inputs)\n",
    "        train_prec, train_rcll = report(targets, preds, shuffle_mask)\n",
    "\n",
    "        inputs, targets, shuffle_mask = X_val[shuffle].to(device), A_val[shuffle].to(device), mask_val[shuffle]\n",
    "        preds = model(inputs)\n",
    "        val_loss = loss_fn(preds[shuffle_mask], targets[shuffle_mask])\n",
    "        val_prec, val_rcll = report(targets, preds, shuffle_mask)\n",
    "\n",
    "    if t % print_every == 0 or t == 1: print(\n",
    "        'Epoch {:3d} | '.format(t) \n",
    "        + 'tr xe: {:.4f}; val xe: {:.4f}; '.format(train_loss.item(), val_loss.item())\n",
    "        + 'tr recall: {:.4f}; val recall: {:.4f}; '.format(train_rcll, val_rcll)\n",
    "        + 'tr prec: {:.4f}; val prec: {:.4f}'.format(train_prec, val_prec)\n",
    "    )\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs, targets = X_te.to(device), A_te.to(device)\n",
    "    preds = model(inputs)\n",
    "    test_prec, test_rcll = report(targets, preds, mask_te)\n",
    "    print('test recall: {:.4f}; test prec: {:.4f}'.format(test_rcll, test_prec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsc80')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eb5c4403b148c92508d1229a3ce9db6ac989f594d65cf46884d2594c7385210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
