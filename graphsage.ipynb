{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from graphsage.encoders import Encoder\n",
    "from graphsage.aggregators import MeanAggregator\n",
    "from graphsage.spv_graphsage import SupervisedGraphSage\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Pubmed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GraphSage on node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_data shape: (2708, 1433)\n",
      "labels shape: (2708, 1)\n",
      "adj_lists type: <class 'collections.defaultdict'>\n"
     ]
    }
   ],
   "source": [
    "if data_name == 'Cora':\n",
    "    # load cora\n",
    "    num_nodes = 2708\n",
    "    num_feats = 1433\n",
    "    num_classes = 7\n",
    "    feat_data = np.zeros((num_nodes, num_feats))\n",
    "    labels = np.empty((num_nodes,1), dtype=np.int64)\n",
    "    node_map = {}\n",
    "    label_map = {}\n",
    "    with open(\"./data/cora_gsg/cora.content\") as fp:\n",
    "        for i,line in enumerate(fp):\n",
    "            info = line.strip().split()\n",
    "            feat_data[i,:] = [float(x) for x in info[1:-1]]\n",
    "            node_map[info[0]] = i\n",
    "            if not info[-1] in label_map:\n",
    "                label_map[info[-1]] = len(label_map)\n",
    "            labels[i] = label_map[info[-1]]\n",
    "\n",
    "    adj_lists = defaultdict(set)\n",
    "    with open(\"./data/cora_gsg/cora.cites\") as fp:\n",
    "        for i,line in enumerate(fp):\n",
    "            info = line.strip().split()\n",
    "            paper1 = node_map[info[0]]\n",
    "            paper2 = node_map[info[1]]\n",
    "            adj_lists[paper1].add(paper2)\n",
    "            adj_lists[paper2].add(paper1)\n",
    "    print('feat_data shape:', feat_data.shape)\n",
    "    print('labels shape:', labels.shape)\n",
    "    print('adj_lists type:', type(adj_lists))\n",
    "elif data_name == 'Pubmed':\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 | xe: 1.930618\n",
      "batch 25 | xe: 0.939674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/popcornfury/Documents/course_materials/current_tasks/dsc180a_q1project/graphsage/encoders.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 50 | xe: 0.261618\n",
      "batch 75 | xe: 0.072758\n",
      "batch 100 | xe: 0.089928\n",
      "batch 125 | xe: 0.031390\n",
      "batch 150 | xe: 0.013784\n",
      "batch 175 | xe: 0.003537\n",
      "batch 200 | xe: 0.116970\n",
      "batch 225 | xe: 0.019461\n",
      "batch 250 | xe: 0.004817\n",
      "batch 275 | xe: 0.021583\n",
      "batch 300 | xe: 0.017895\n",
      "batch 325 | xe: 0.002445\n",
      "batch 350 | xe: 0.004432\n",
      "batch 375 | xe: 0.080515\n",
      "batch 400 | xe: 0.007993\n",
      "batch 425 | xe: 0.014591\n",
      "batch 450 | xe: 0.001856\n",
      "batch 475 | xe: 0.003758\n",
      "batch 500 | xe: 0.024429\n",
      "tr precision: 0.7740; tr recall: 0.7740; tr f1: 0.7740\n",
      "val precision: 0.7740; val recall: 0.7740; val f1: 0.7740\n",
      "average batch time: 0.002294099807739258\n"
     ]
    }
   ],
   "source": [
    "# run cora\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "features = nn.Embedding(num_nodes, num_feats)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "\n",
    "agg1 = MeanAggregator(features, cuda=True)\n",
    "enc1 = Encoder(features, num_feats, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "enc2 = Encoder(\n",
    "        lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "        base_model=enc1, gcn=True, cuda=False)\n",
    "enc1.num_samples = 5\n",
    "enc2.num_samples = 5\n",
    "\n",
    "graphsage = SupervisedGraphSage(num_classes, enc2)\n",
    "rand_indices = np.array(range(num_nodes))\n",
    "train = list(rand_indices[:140])\n",
    "val = rand_indices[140:640]\n",
    "test = rand_indices[-1000:]\n",
    "batch_size = 32\n",
    "\n",
    "# optimizer = torch.optim.SGD(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.7)\n",
    "optimizer = torch.optim.Adam(graphsage.parameters(), lr=1e-3)\n",
    "print_every = 25\n",
    "epochs = 500\n",
    "for batch in range(1, epochs + 1):\n",
    "    batch_nodes = train[:batch_size]\n",
    "    random.shuffle(train)\n",
    "    optimizer.zero_grad()\n",
    "    loss = graphsage.loss(\n",
    "        batch_nodes, \n",
    "        Variable(torch.LongTensor(labels[np.array(batch_nodes)]))\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch == 1 or batch % print_every == 0:\n",
    "        print('batch {} | xe: {:.6f}'.format(batch, loss.data.item()))\n",
    "\n",
    "# tr_output = graphsage.forward(train)\n",
    "# val_output = graphsage.forward(val) \n",
    "\n",
    "# tr_acc = accuracy_score(labels[train], tr_output.data.numpy().argmax(axis=1))\n",
    "# val_acc = accuracy_score(labels[val], val_output.data.numpy().argmax(axis=1))\n",
    "# print('tr acc: {:.4f}'.format(tr_acc))\n",
    "# print('val acc: {:.4f}'.format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test quality of GraphSage embeddings for node classification via LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = graphsage.enc(train + val.tolist()).t().detach().numpy()\n",
    "X_te = graphsage.enc(test).t().detach().numpy()\n",
    "y_tr = labels[np.array(train + val.tolist())].squeeze()\n",
    "y_te = labels[np.array(test)].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9890625, 0.737)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(class_weight='balanced', max_iter=750).fit(X_tr, y_tr)\n",
    "clf.score(X_tr, y_tr), clf.score(X_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GraphSage on link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid('./data', data_name)\n",
    "data = dataset[0]\n",
    "\n",
    "feat_data = data.x\n",
    "adj_lists = data.edge_index\n",
    "labels = data.y\n",
    "num_nodes, num_features = feat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(640)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.train_mask + data.val_mask).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 640/640 [00:29<00:00, 21.40it/s]\n",
      "100%|██████████| 1000/1000 [00:50<00:00, 19.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(382, 640, 692, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_edges(edge_index, mask, strict=False):\n",
    "    pos_samples, neg_samples = [], []\n",
    "    if strict: candidates = mask.nonzero().squeeze()\n",
    "    for node in tqdm(mask.nonzero()):\n",
    "        neighbors = edge_index[:, edge_index[0] == node][1]\n",
    "        not_neighbors = edge_index[:, edge_index[0] != node][1]\n",
    "        if strict:\n",
    "            neighbors = [n for n in neighbors if n in candidates]\n",
    "            not_neighbors = [n for n in not_neighbors if n in candidates]\n",
    "\n",
    "        num_neighbors = len(neighbors)\n",
    "        if strict and num_neighbors > 0:\n",
    "            pos = neighbors[random.sample(range(num_neighbors), 1)[0]].item()\n",
    "            pos_samples.append([node.item(), pos])\n",
    "        \n",
    "        num_not_neighbors = len(not_neighbors)\n",
    "        if strict and num_not_neighbors > 0:\n",
    "            neg = not_neighbors[random.sample(range(num_not_neighbors), 1)[0]].item()\n",
    "            neg_samples.append([node.item(), neg])\n",
    "\n",
    "    return pos_samples, neg_samples\n",
    "\n",
    "pos_samples_tr, neg_samples_tr = sample_edges(adj_lists, data.train_mask + data.val_mask, strict=True)\n",
    "pos_samples_te, neg_samples_te = sample_edges(adj_lists, data.test_mask, strict=True)\n",
    "len(pos_samples_tr), len(neg_samples_tr), len(pos_samples_te), len(neg_samples_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_embeddings shape: torch.Size([2708, 128])\n"
     ]
    }
   ],
   "source": [
    "node_embeddings = graphsage.enc(list(range(num_nodes))).t().detach()\n",
    "print('node_embeddings shape:', node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pos_hdmd_tr = node_embeddings[pos_samples_tr, :][:, 0, :] * node_embeddings[pos_samples_tr, :][:, 1, :]\n",
    "embeddings_neg_hdmd_tr = node_embeddings[neg_samples_tr, :][:, 0, :] * node_embeddings[neg_samples_tr, :][:, 1, :]\n",
    "embeddings_pos_hdmd_te = node_embeddings[pos_samples_te, :][:, 0, :] * node_embeddings[pos_samples_te, :][:, 1, :]\n",
    "embeddings_neg_hdmd_te = node_embeddings[neg_samples_te, :][:, 0, :] * node_embeddings[neg_samples_te, :][:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_hdmd_tr = np.concatenate([\n",
    "    embeddings_pos_hdmd_tr, \n",
    "    embeddings_neg_hdmd_tr\n",
    "])\n",
    "\n",
    "targets_tr = np.concatenate([\n",
    "    np.ones(len(embeddings_pos_hdmd_tr)),\n",
    "    np.zeros(len(embeddings_neg_hdmd_tr)),\n",
    "])\n",
    "\n",
    "embeddings_hdmd_te = np.concatenate([\n",
    "    embeddings_pos_hdmd_te,\n",
    "    embeddings_neg_hdmd_te\n",
    "])\n",
    "\n",
    "targets_te = np.concatenate([\n",
    "    np.ones(len(embeddings_pos_hdmd_te)),\n",
    "    np.zeros(len(embeddings_neg_hdmd_te))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/popcornfury/miniforge3/envs/dsc80/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6487279843444227, 0.5218676122931442)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(class_weight='balanced', max_iter=500).fit(embeddings_hdmd_tr, targets_tr)\n",
    "tr_outputs = clf.predict(embeddings_hdmd_tr)\n",
    "te_outputs = clf.predict(embeddings_hdmd_te)\n",
    "\n",
    "tr_prec, tr_recall, _, _ = precision_recall_fscore_support(targets_tr, tr_outputs, average=\"micro\")\n",
    "val_prec, val_recall, _, _ = precision_recall_fscore_support(targets_te, te_outputs, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 13,  22,  47, 151, 303, 447, 500, 500, 500, 500],\n",
       "        [ 13,  24,  45, 116, 213, 381, 500, 500, 500, 500],\n",
       "        [ 13,  23,  46, 128, 280, 453, 500, 500, 500, 500],\n",
       "        [ 13,  23,  52, 121, 241, 445, 500, 500, 500, 500],\n",
       "        [ 13,  23,  59, 122, 258, 355, 500, 500, 500, 500]]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsc80')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eb5c4403b148c92508d1229a3ce9db6ac989f594d65cf46884d2594c7385210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
